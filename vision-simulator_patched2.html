        // Function to detect camera type and calculate FOV
        function detectCameraAndFOV(exifData) {
            const make = (exifData.Make || '').trim();
            const model = (exifData.Model || '').trim();
            const focalLength = exifData.FocalLength;
            const focalLength35mm = exifData.FocalLengthIn35mmFilm;
            
            // Detect image orientation from dimensions
            let isPortrait = false;
            if (originalImage) {
                isPortrait = originalImage.height > originalImage.width;
            }
            
            console.log('Detection attempt - Make:', make, 'Model:', model, 'FL:', focalLength);
            console.log('Image orientation:', isPortrait ? 'Portrait' : 'Landscape');
            
            let cameraInfo = 'Unknown';
            let fovH = null;  // Horizontal FOV
            let fovV = null;  // Vertical FOV
            let sensorWidth = null;
            let sensorHeight = null;
            let sensorData = null;
            
            // Check if it's a traditional camera - now with better matching
            if (make.match(/Canon|CANON|Nikon|NIKON|Sony|SONY|Fuji|FUJIFILM|Pentax|PENTAX|Olympus|OLYMPUS|Panasonic/i)) {
                // First try exact match with model
                for (let cam in CAMERA_SENSORS) {
                    if (model.toUpperCase().includes(cam.toUpperCase())) {
                        sensorData = CAMERA_SENSORS[cam];
                        sensorWidth = sensorData.w;
                        sensorHeight = sensorData.h;
                        cameraInfo = `${make} ${model} (${sensorWidth}×${sensorHeight}mm)`;
                        console.log('Found exact match:', cam, 'Sensor:', sensorWidth + '×' + sensorHeight);
                        break;
                    }
                }
                
                // If not found, try pattern matching with default aspect ratios
                if (!sensorData) {
                    const makeUpper = make.toUpperCase();
                    const modelUpper = model.toUpperCase();
                    
                    if (makeUpper.includes('CANON')) {
                        if (modelUpper.match(/\b(R5|R6|R3|5D|6D|1D[XS]?)\b/) || modelUpper.includes('MARK')) {
                            sensorWidth = 36;
                            sensorHeight = 24; // 3:2 aspect
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else if (modelUpper.match(/\b(R7|R10|[789]0D|[78]00D|[78]50D|7D|REBEL|KISS)\b/)) {
                            sensorWidth = 22.2;
                            sensorHeight = 14.8; // 3:2 aspect
                            cameraInfo = `${make} ${model} (APS-C)`;
                        }
                    } else if (makeUpper.includes('NIKON')) {
                        if (modelUpper.match(/\b(Z[5-9]|D[86]|D[78][0-9]0|DF)\b/)) {
                            sensorWidth = 36;
                            sensorHeight = 24;
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else if (modelUpper.match(/\b(Z[35]0|Z ?FC|D[357][0-9]00|D500)\b/)) {
                            sensorWidth = 23.6;
                            sensorHeight = 15.7;
                            cameraInfo = `${make} ${model} (APS-C DX)`;
                        }
                    } else if (makeUpper.includes('SONY')) {
                        if (modelUpper.match(/\b(A7|A9|A1|ILCE-7)\b/)) {
                            sensorWidth = 36;
                            sensorHeight = 24;
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else if (modelUpper.match(/\b(A6[0-9]|ILCE-6[0-9])\b/)) {
                            sensorWidth = 23.6;
                            sensorHeight = 15.6;
                            cameraInfo = `${make} ${model} (APS-C)`;
                        }
                    } else if (makeUpper.includes('FUJI')) {
                        if (modelUpper.includes('GFX')) {
                            sensorWidth = 43.8;
                            sensorHeight = 32.9; // 4:3 aspect
                            cameraInfo = `${make} ${model} (Medium Format)`;
                        } else {
                            sensorWidth = 23.6;
                            sensorHeight = 15.6;
                            cameraInfo = `${make} ${model} (APS-C)`;
                        }
                    } else if (makeUpper.includes('OLYMPUS') || (makeUpper.includes('PANASONIC') && modelUpper.match(/\b(G[HX]?[0-9])\b/))) {
                        sensorWidth = 17.3;
                        sensorHeight = 13; // 4:3 aspect
                        cameraInfo = `${make} ${model} (Micro 4/3)`;
                    } else if (makeUpper.includes('PANASONIC') && modelUpper.match(/\b(S[15])\b/)) {
                        sensorWidth = 36;
                        sensorHeight = 24;
                        cameraInfo = `${make} ${model} (Full Frame)`;
                    } else if (makeUpper.includes('PENTAX')) {
                        if (modelUpper.includes('K-1')) {
                            sensorWidth = 36;
                            sensorHeight = 24;
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else {
                            sensorWidth = 23.6;
                            sensor<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vision Condition Simulator</title>
    <script src="https://cdn.jsdelivr.net/npm/exif-js@2.3.0/exif.js">function applyVeilingGlare(imageData, strength = 0.25, sigmaDeg = 15) {
  const pxPerDeg = (typeof window.currentPixelsPerDegree === 'number' && window.currentPixelsPerDegree>0)
    ? window.currentPixelsPerDegree
    : (imageData.width / ((typeof detectedFieldOfView==='number'?detectedFieldOfView:60)));
  const sigmaPx = Math.max(1, sigmaDeg * pxPerDeg);
  const blurred = gaussianBlur(new ImageData(new Uint8ClampedArray(imageData.data), imageData.width, imageData.height), sigmaPx);
  const a = Math.max(0, Math.min(1, strength));
  const d = imageData.data, b = blurred.data;
  for (let i=0;i<d.length;i+=4){
    d[i]   = d[i]*(1-a)   + b[i]*a;
    d[i+1] = d[i+1]*(1-a) + b[i+1]*a;
    d[i+2] = d[i+2]*(1-a) + b[i+2]*a;
  }
  return imageData;
}

function toGrayscale(imageData) {
  const w = imageData.width, h = imageData.height, d = imageData.data;
  const g = new Float32Array(w*h);
  for (let i=0, p=0; i<d.length; i+=4, p++){
    g[p] = 0.299*d[i] + 0.587*d[i+1] + 0.114*d[i+2];
  }
  return {w, h, g};
}
function sobelMagnitude(gray) {
  const {w,h,g} = gray;
  const out = new Float32Array(w*h);
  for (let y=1;y<h-1;y++){
    for (let x=1;x<w-1;x++){
      const i = y*w + x;
      const gx = -g[i-w-1] -2*g[i-1] - g[i+w-1] + g[i-w+1] + 2*g[i+1] + g[i+w+1];
      const gy = -g[i-w-1] -2*g[i-w] - g[i-w+1] + g[i+w-1] + 2*g[i+w] + g[i+w+1];
      out[i] = Math.hypot(gx, gy);
    }
  }
  return {w,h,mag:out};
}
function applyEdgeHazardOverlay(origData, simData, sensitivity=50) {
  // sensitivity 0..100 controls how easily an edge is flagged
  const w = simData.width, h = simData.height;
  const o = toGrayscale(origData); const s = toGrayscale(simData);
  const Om = sobelMagnitude(o).mag, Sm = sobelMagnitude(s).mag;

  // thresholds
  const high = 100; // strong edge in original
  const low = 20 + (120-20)*(1 - sensitivity/100); // low threshold in simulated

  const D = simData.data;
  for (let y=1;y<h-1;y++){
    for (let x=1;x<w-1;x++){
      const i = y*w + x;
      if (Om[i] >= high && Sm[i] < low) {
        const idx = i*4;
        // overlay red marker (alpha-blend)
        D[idx]   = Math.min(255, D[idx]*0.5 + 255*0.5);
        D[idx+1] = Math.min(255, D[idx+1]*0.5 + 0*0.5);
        D[idx+2] = Math.min(255, D[idx+2]*0.5 + 0*0.5);
      }
    }
  }
  return simData;
}

</script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }
        
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }
        
        .subtitle {
            font-size: 1.1em;
            opacity: 0.9;
        }
        
        .main-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            padding: 30px;
        }
        
        @media (max-width: 900px) {
            .main-content {
                grid-template-columns: 1fr;
            }
        }
        
        .image-panel {
            background: white;
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.1);
        }
        
        .panel-title {
            font-size: 1.3em;
            font-weight: 600;
            margin-bottom: 15px;
            color: #333;
        }
        
        .upload-area {
            border: 3px dashed #667eea;
            border-radius: 10px;
            padding: 40px;
            text-align: center;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            cursor: pointer;
            transition: all 0.3s ease;
            margin-bottom: 20px;
        }
        
        .upload-area:hover {
            border-color: #764ba2;
            transform: scale(1.02);
        }
        
        .upload-area.dragover {
            background: linear-gradient(135deg, #667eea20 0%, #764ba220 100%);
            border-color: #764ba2;
        }
        
        .upload-icon {
            font-size: 3em;
            margin-bottom: 10px;
        }
        
        canvas {
            width: 100%;
            height: auto;
            border-radius: 10px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
            background: #f0f0f0;
            display: block;
        }
        
        .controls {
            background: white;
            border-radius: 15px;
            padding: 25px;
            margin: 0 30px 30px;
            box-shadow: 0 5px 20px rgba(0, 0, 0, 0.1);
        }
        
        .control-section {
            margin-bottom: 25px;
            padding-bottom: 25px;
            border-bottom: 1px solid #e0e0e0;
        }
        
        .control-section:last-child {
            border-bottom: none;
            margin-bottom: 0;
            padding-bottom: 0;
        }
        
        .section-title {
            font-size: 1.2em;
            font-weight: 600;
            margin-bottom: 15px;
            color: #667eea;
        }
        
        .control-group {
            margin-bottom: 15px;
        }
        
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: 500;
            color: #555;
        }
        
        .slider-container {
            display: flex;
            align-items: center;
            gap: 15px;
        }
        
        input[type="range"] {
            flex: 1;
            -webkit-appearance: none;
            height: 8px;
            border-radius: 5px;
            background: linear-gradient(to right, #667eea 0%, #764ba2 100%);
            outline: none;
        }
        
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: white;
            border: 3px solid #667eea;
            cursor: pointer;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
        }
        
        input[type="range"]::-moz-range-thumb {
            width: 20px;
            height: 20px;
            border-radius: 50%;
            background: white;
            border: 3px solid #667eea;
            cursor: pointer;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
        }
        
        .value-display {
            min-width: 80px;
            padding: 5px 10px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 20px;
            text-align: center;
            font-weight: 600;
        }
        
        select {
            width: 100%;
            padding: 10px;
            border: 2px solid #667eea;
            border-radius: 8px;
            font-size: 1em;
            background: white;
            cursor: pointer;
        }
        
        .button-group {
            display: flex;
            gap: 10px;
            margin-top: 20px;
        }
        
        button {
            flex: 1;
            padding: 12px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }
        
        button:active {
            transform: translateY(0);
        }
        
        button.secondary {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        }
        
        .info-box {
            background: linear-gradient(135deg, #667eea20 0%, #764ba220 100%);
            border-left: 4px solid #667eea;
            padding: 15px;
            border-radius: 8px;
            margin-top: 15px;
        }
        
        .info-box p {
            margin: 5px 0;
            color: #555;
        }
        
        .loading {
            display: none;
            text-align: center;
            padding: 20px;
            color: #667eea;
            font-weight: 600;
        }
        
        .spinner {
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 10px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        input[type="file"] {
            display: none;
        }

        .checkbox-group {
            display: flex;
            align-items: center;
            gap: 10px;
            margin: 10px 0;
        }

        input[type="checkbox"] {
            width: 20px;
            height: 20px;
            cursor: pointer;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>👁️ Vision Condition Simulator for Interior Spaces</h1>
            <p class="subtitle">Evaluate how vision conditions affect perception of architectural designs</p>
        </header>
        
        <div class="main-content">
            <div class="image-panel">
                <h2 class="panel-title">Original Image</h2>
                <div class="upload-area" id="uploadArea">
                    <div class="upload-icon">📷</div>
                    <p><strong>Drop an image here</strong></p>
                    <p>or click to browse</p>
                    <p style="font-size: 0.9em; margin-top: 10px; opacity: 0.8;">Supports: Phone photos, Revit/Enscape renders, or any interior image</p>
                    <input type="file" id="fileInput" accept="image/*">
                </div>
                <canvas id="originalCanvas"></canvas>
            </div>
            
            <div class="image-panel">
                <h2 class="panel-title">Simulated Vision</h2>
                <div class="loading" id="loading">
                    <div class="spinner"></div>
                    <p>Processing image...</p>
                </div>
                <canvas id="simulatedCanvas"></canvas>
            </div>
        </div>
        
        <div class="controls">
            <div class="control-section">
                <h3 class="section-title">Camera Detection & Field of View</h3>
                
                <div class="control-group">
                    <label>Camera Type: <span id="cameraType" style="font-weight: bold;">Not detected</span></label>
                </div>
                
                <div class="control-group">
                    <label>Detected FOV: <span id="detectedFOV" style="font-weight: bold;">--</span></label>
                </div>
                
                <div class="control-group">
                    <label for="fovOverride">Manual FOV Override (degrees):</label>
                    <div class="slider-container">
                        <input type="range" id="fovOverride" min="10" max="180" step="5" value="60">
                        <input type="number" id="fovInput" min="10" max="180" value="60" style="width: 70px; padding: 5px; margin-left: 10px;">
                    </div>
                    <small style="color: #666;">For renders or if camera not detected. Typical: Phone main ~80°, Ultra-wide ~120°, Interior render ~60-90°</small>
                </div>
            </div>
            
            <div class="control-section">
                <h3 class="section-title">Vision Condition</h3>
                <div class="control-group">
                    <label for="condition">Select Condition:</label>
                    <select id="condition">
                        <option value="acuity">Visual Acuity Loss</option>
                        <option value="cataracts">Cataracts</option>
                        <option value="diabetic">Diabetic Retinopathy</option>
                        <option value="macular">Macular Degeneration</option>
                        <option value="glaucoma">Glaucoma</option>
                        <option value="custom">Custom Parameters</option>
                    </select>
                </div>
            </div>
            
            <div class="control-section">
                <h3 class="section-title">Visual Parameters</h3>
                
                <div class="control-group">
                    <label for="acuity">Visual Acuity (Snellen):</label>
                    <div class="slider-container">
                        <input type="range" id="acuity" min="0" max="2.0" step="0.05" value="0">
                        <div class="value-display" id="acuityValue">20/20</div>
                    </div>
                </div>
                
                <div class="control-group">
                    <label for="contrast">Contrast Sensitivity (Pelli-Robson):</label>
                    <div class="slider-container">
                        <input type="range" id="contrast" min="0" max="2.0" step="0.05" value="2.0">
                        <div class="value-display" id="contrastValue">2.00</div>
                    </div>
                </div>
                
                <div class="control-group">
                    <label for="saturation">Color Saturation:</label>
                    <div class="slider-container">
                        <input type="range" id="saturation" min="0" max="100" step="5" value="100">
                        <div class="value-display" id="saturationValue">100%</div>
                    </div>
                </div>

                <div class="control-group">
                    <label for="fieldLoss">Field of View Loss:</label>
                    <div class="slider-container">
                        <input type="range" id="fieldLoss" min="0" max="100" step="5" value="0">
                        <div class="value-display" id="fieldLossValue">0%</div>
                <div class="control-group">
                    <label>Edge Hazard Overlay (beta)</label>
                    <div style="display:flex; align-items:center; gap:12px; flex-wrap:wrap;">
                        <label style="display:flex; align-items:center; gap:8px;">
                            <input type="checkbox" id="edgeOverlay"> Show hazard edges
                        </label>
                        <label style="display:flex; align-items:center; gap:8px;">
                            Sensitivity:
                            <input type="range" id="edgeSensitivity" min="0" max="100" value="50" step="1" style="width:160px;">
                        </label>
                    </div>
                    <div style="font-size:12px;color:#666;margin-top:4px;">Marks edges that are strong in the original but weak after simulation (useful for low-acuity & cataracts).</div>
                </div>

                    </div>
                </div>
            </div>
            
            <div class="control-section">
                <h3 class="section-title">Condition-Specific Effects</h3>
                
                <div class="checkbox-group">
                    <input type="checkbox" id="yellowing">
                    <label for="yellowing">Lens Yellowing (Cataracts)</label>
                </div>
                
                <div class="checkbox-group">
                    <input type="checkbox" id="floaters">
                    <label for="floaters">Floaters/Hemorrhages (Diabetic)</label>
                </div>
                
                <div class="checkbox-group">
                    <input type="checkbox" id="centralScotoma">
                    <label for="centralScotoma">Central Scotoma (Macular)</label>
                </div>
            </div>
            
            <div class="info-box">
                <p><strong>logMAR:</strong> <span id="logmarInfo">0.00</span></p>
                <p><strong>Cycles per Degree:</strong> <span id="cpdInfo">30.00</span></p>
                <p><strong>Blur Sigma:</strong> <span id="sigmaInfo">0.00</span> pixels</p>
            </div>
            
            <div class="info-box" style="margin-top: 15px; background: linear-gradient(135deg, #f093fb20 0%, #f5576c20 100%); border-left-color: #f5576c;">
                <p><strong>Design Considerations:</strong></p>
                <p>• Check visibility of: stairs, edges, doorways, signage</p>
                <p>• Ensure adequate contrast between surfaces</p>
                <p>• Verify lighting levels for navigation</p>
                <p>• Note: 20/70 or worse = legal blindness in many regions</p>
            </div>
            
            <div class="button-group">
                <button onclick="applySimulation()">Apply Simulation</button>
                <button class="secondary" onclick="resetImage()">Reset</button>
                <button class="secondary" onclick="downloadImage()">Download Result</button>
            </div>
        </div>
    </div>

    <script>
        let originalImage = null;
        let originalCanvas = null;
        let simulatedCanvas = null;
        let originalCtx = null;
        let simulatedCtx = null;
        let detectedFieldOfView = 60; // Default FOV

        // Camera sensor database (2018+ flagship phones) - NOW WITH HEIGHT
        const PHONE_SENSORS = {
            // Apple iPhones (sensor width × height in mm)
            'Apple': {
                // iPhone 16 series - 4:3 aspect ratio
                'iPhone16,2': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 4.2, h: 3.2} }, // 16 Pro
                'iPhone16,1': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 4.2, h: 3.2} }, // 16 Pro Max
                // iPhone 15 series
                'iPhone15,3': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 4.2, h: 3.2} }, // 15 Pro
                'iPhone15,4': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 4.2, h: 3.2} }, // 15 Pro Max
                // iPhone 14 series
                'iPhone14,6': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // 14 Pro
                'iPhone14,7': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // 14 Pro Max
                // iPhone 13 series
                'iPhone13,3': { main: {w: 7.5, h: 5.6}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // 13 Pro
                'iPhone13,4': { main: {w: 7.5, h: 5.6}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // 13 Pro Max
            },
            'samsung': {
                // Galaxy S24 series - 4:3 aspect ratio
                'SM-S928': { main: {w: 9.6, h: 7.2}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 5.8, h: 4.4} }, // S24 Ultra
                'SM-S926': { main: {w: 7.5, h: 5.6}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // S24+
                // Galaxy S23 series
                'SM-S918': { main: {w: 9.6, h: 7.2}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // S23 Ultra
                'SM-S916': { main: {w: 7.5, h: 5.6}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // S23+
                // Galaxy S22 series
                'SM-S908': { main: {w: 9.6, h: 7.2}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // S22 Ultra
                // Galaxy S21 series
                'SM-G998': { main: {w: 9.6, h: 7.2}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 3.5, h: 2.6} }, // S21 Ultra
            },
            'Google': {
                // Pixel series - 4:3 aspect ratio
                'Pixel 9 Pro': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 5.7, h: 4.3} },
                'Pixel 9 Pro XL': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 5.7, h: 4.3} },
                'Pixel 8 Pro': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 5.7, h: 4.3} },
                'Pixel 8': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3} },
                'Pixel 7 Pro': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.7, h: 4.3}, tele: {w: 5.7, h: 4.3} },
                'Pixel 6 Pro': { main: {w: 9.8, h: 7.3}, ultrawide: {w: 5.0, h: 3.8}, tele: {w: 5.0, h: 3.8} },
            }
        };

        // DSLR/Mirrorless sensor sizes (width × height in mm) - EXPANDED DATABASE
        const CAMERA_SENSORS = {
            // Canon Full Frame (36×24mm - 3:2 aspect ratio)
            'Canon EOS R5': {w: 36, h: 24}, 'Canon EOS R6': {w: 36, h: 24}, 'Canon EOS R3': {w: 36, h: 24},
            'Canon EOS 5D Mark IV': {w: 36, h: 24}, 'Canon EOS 5D Mark III': {w: 36, h: 24},
            'Canon EOS 6D Mark II': {w: 36, h: 24}, 'Canon EOS 6D': {w: 36, h: 24},
            'Canon EOS-1D X Mark III': {w: 36, h: 24}, 'Canon EOS-1D X Mark II': {w: 36, h: 24},
            // Canon APS-C (22.2×14.8mm - 3:2 aspect ratio)
            'Canon EOS R7': {w: 22.2, h: 14.8}, 'Canon EOS R10': {w: 22.2, h: 14.8},
            'Canon EOS 90D': {w: 22.2, h: 14.8}, 'Canon EOS 80D': {w: 22.2, h: 14.8}, 'Canon EOS 70D': {w: 22.2, h: 14.8},
            'Canon EOS 7D Mark II': {w: 22.2, h: 14.8}, 'Canon EOS 7D': {w: 22.2, h: 14.8},
            'Canon EOS Rebel': {w: 22.2, h: 14.8}, // Catches all Rebel models
            'Canon EOS 850D': {w: 22.2, h: 14.8}, 'Canon EOS 800D': {w: 22.2, h: 14.8},
            // Nikon Full Frame (36×24mm)
            'NIKON Z 9': {w: 36, h: 24}, 'NIKON Z 8': {w: 36, h: 24}, 'NIKON Z 7': {w: 36, h: 24}, 'NIKON Z 6': {w: 36, h: 24},
            'NIKON Z 5': {w: 36, h: 24}, 'NIKON Z 7II': {w: 36, h: 24}, 'NIKON Z 6II': {w: 36, h: 24},
            'NIKON D850': {w: 36, h: 24}, 'NIKON D780': {w: 36, h: 24}, 'NIKON D750': {w: 36, h: 24},
            'NIKON D810': {w: 36, h: 24}, 'NIKON D800': {w: 36, h: 24}, 'NIKON D610': {w: 36, h: 24},
            'NIKON Df': {w: 36, h: 24}, 'NIKON D6': {w: 36, h: 24}, 'NIKON D5': {w: 36, h: 24},
            // Nikon APS-C DX (23.6×15.7mm)
            'NIKON Z 50': {w: 23.6, h: 15.7}, 'NIKON Z 30': {w: 23.6, h: 15.7}, 'NIKON Z fc': {w: 23.6, h: 15.7},
            'NIKON D7500': {w: 23.6, h: 15.7}, 'NIKON D7200': {w: 23.6, h: 15.7}, 'NIKON D7100': {w: 23.6, h: 15.7},
            'NIKON D5600': {w: 23.6, h: 15.7}, 'NIKON D5500': {w: 23.6, h: 15.7}, 'NIKON D5300': {w: 23.6, h: 15.7},
            'NIKON D3500': {w: 23.6, h: 15.7}, 'NIKON D3400': {w: 23.6, h: 15.7}, 'NIKON D3300': {w: 23.6, h: 15.7},
            'NIKON D500': {w: 23.6, h: 15.7},
            // Sony Full Frame (36×24mm)
            'SONY A7R V': {w: 36, h: 24}, 'SONY A7R IV': {w: 36, h: 24}, 'SONY A7R III': {w: 36, h: 24},
            'SONY A7 IV': {w: 36, h: 24}, 'SONY A7 III': {w: 36, h: 24}, 'SONY A7C': {w: 36, h: 24},
            'SONY A7S III': {w: 36, h: 24}, 'SONY A9 II': {w: 36, h: 24}, 'SONY A9': {w: 36, h: 24},
            'SONY A1': {w: 36, h: 24}, 'SONY ILCE-7': {w: 36, h: 24}, // Generic A7
            // Sony APS-C (23.6×15.6mm)
            'SONY A6700': {w: 23.6, h: 15.6}, 'SONY A6600': {w: 23.6, h: 15.6}, 'SONY A6500': {w: 23.6, h: 15.6},
            'SONY A6400': {w: 23.6, h: 15.6}, 'SONY A6300': {w: 23.6, h: 15.6}, 'SONY A6100': {w: 23.6, h: 15.6},
            'SONY A6000': {w: 23.6, h: 15.6}, 'SONY ILCE-6': {w: 23.6, h: 15.6}, // Generic A6xxx
            // Fujifilm APS-C (23.6×15.6mm)
            'FUJIFILM X-T5': {w: 23.6, h: 15.6}, 'FUJIFILM X-T4': {w: 23.6, h: 15.6}, 'FUJIFILM X-T3': {w: 23.6, h: 15.6},
            'FUJIFILM X-T30': {w: 23.6, h: 15.6}, 'FUJIFILM X-S20': {w: 23.6, h: 15.6}, 'FUJIFILM X-S10': {w: 23.6, h: 15.6},
            'FUJIFILM X-H2': {w: 23.6, h: 15.6}, 'FUJIFILM X-H2S': {w: 23.6, h: 15.6}, 'FUJIFILM X-H1': {w: 23.6, h: 15.6},
            'FUJIFILM X-Pro3': {w: 23.6, h: 15.6}, 'FUJIFILM X-Pro2': {w: 23.6, h: 15.6},
            'FUJIFILM X100V': {w: 23.6, h: 15.6}, 'FUJIFILM X100F': {w: 23.6, h: 15.6},
            // Fujifilm Medium Format (43.8×32.9mm - 4:3 aspect)
            'FUJIFILM GFX100': {w: 43.8, h: 32.9}, 'FUJIFILM GFX100S': {w: 43.8, h: 32.9}, 'FUJIFILM GFX50S': {w: 43.8, h: 32.9},
            // Micro 4/3 (17.3×13mm - 4:3 aspect)
            'OLYMPUS OM-1': {w: 17.3, h: 13}, 'OLYMPUS E-M1': {w: 17.3, h: 13}, 'OLYMPUS E-M5': {w: 17.3, h: 13},
            'Panasonic GH6': {w: 17.3, h: 13}, 'Panasonic GH5': {w: 17.3, h: 13}, 'Panasonic G9': {w: 17.3, h: 13},
            'Panasonic S5': {w: 36, h: 24}, 'Panasonic S1': {w: 36, h: 24}, // Full frame Panasonic
            // Pentax
            'PENTAX K-1': {w: 36, h: 24}, 'PENTAX K-1 Mark II': {w: 36, h: 24},
            'PENTAX K-3': {w: 23.6, h: 15.6}, 'PENTAX K-70': {w: 23.6, h: 15.6},
        };

        // Function to detect camera type and calculate FOV
        function detectCameraAndFOV(exifData) {
            const make = (exifData.Make || '').trim();
            const model = (exifData.Model || '').trim();
            const focalLength = exifData.FocalLength;
            const focalLength35mm = exifData.FocalLengthIn35mmFilm;
            
            // Detect image orientation from dimensions
            let isPortrait = false;
            if (originalImage) {
                isPortrait = originalImage.height > originalImage.width;
            }
            
            console.log('Detection attempt - Make:', make, 'Model:', model, 'FL:', focalLength);
            console.log('Image orientation:', isPortrait ? 'Portrait' : 'Landscape');
            
            let cameraInfo = 'Unknown';
            let fovH = null;  // Horizontal FOV
            let fovV = null;  // Vertical FOV
            let sensorWidth = null;
            let sensorHeight = null;
            let sensorData = null;
            
            // Check if it's a traditional camera - now with better matching
            if (make.match(/Canon|CANON|Nikon|NIKON|Sony|SONY|Fuji|FUJIFILM|Pentax|PENTAX|Olympus|OLYMPUS|Panasonic/i)) {
                // First try exact match with model
                for (let cam in CAMERA_SENSORS) {
                    if (model.toUpperCase().includes(cam.toUpperCase())) {
                        sensorData = CAMERA_SENSORS[cam];
                        sensorWidth = sensorData.w;
                        sensorHeight = sensorData.h;
                        cameraInfo = `${make} ${model} (${sensorWidth}×${sensorHeight}mm)`;
                        console.log('Found exact match:', cam, 'Sensor:', sensorWidth + '×' + sensorHeight);
                        break;
                    }
                }
                
                // If not found, try pattern matching with default aspect ratios
                if (!sensorData) {
                    const makeUpper = make.toUpperCase();
                    const modelUpper = model.toUpperCase();
                    
                    if (makeUpper.includes('CANON')) {
                        if (modelUpper.match(/\b(R5|R6|R3|5D|6D|1D[XS]?)\b/) || modelUpper.includes('MARK')) {
                            sensorWidth = 36;
                            sensorHeight = 24; // 3:2 aspect
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else if (modelUpper.match(/\b(R7|R10|[789]0D|[78]00D|[78]50D|7D|REBEL|KISS)\b/)) {
                            sensorWidth = 22.2;
                            sensorHeight = 14.8; // 3:2 aspect
                            cameraInfo = `${make} ${model} (APS-C)`;
                        }
                    } else if (makeUpper.includes('NIKON')) {
                        if (modelUpper.match(/\b(Z[5-9]|D[86]|D[78][0-9]0|DF)\b/)) {
                            sensorWidth = 36;
                            sensorHeight = 24;
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else if (modelUpper.match(/\b(Z[35]0|Z ?FC|D[357][0-9]00|D500)\b/)) {
                            sensorWidth = 23.6;
                            sensorHeight = 15.7;
                            cameraInfo = `${make} ${model} (APS-C DX)`;
                        }
                    } else if (makeUpper.includes('SONY')) {
                        if (modelUpper.match(/\b(A7|A9|A1|ILCE-7)\b/)) {
                            sensorWidth = 36;
                            sensorHeight = 24;
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else if (modelUpper.match(/\b(A6[0-9]|ILCE-6[0-9])\b/)) {
                            sensorWidth = 23.6;
                            sensorHeight = 15.6;
                            cameraInfo = `${make} ${model} (APS-C)`;
                        }
                    } else if (makeUpper.includes('FUJI')) {
                        if (modelUpper.includes('GFX')) {
                            sensorWidth = 43.8;
                            sensorHeight = 32.9; // 4:3 aspect
                            cameraInfo = `${make} ${model} (Medium Format)`;
                        } else {
                            sensorWidth = 23.6;
                            sensorHeight = 15.6;
                            cameraInfo = `${make} ${model} (APS-C)`;
                        }
                    } else if (makeUpper.includes('OLYMPUS') || (makeUpper.includes('PANASONIC') && modelUpper.match(/\b(G[HX]?[0-9])\b/))) {
                        sensorWidth = 17.3;
                        sensorHeight = 13; // 4:3 aspect
                        cameraInfo = `${make} ${model} (Micro 4/3)`;
                    } else if (makeUpper.includes('PANASONIC') && modelUpper.match(/\b(S[15])\b/)) {
                        sensorWidth = 36;
                        sensorHeight = 24;
                        cameraInfo = `${make} ${model} (Full Frame)`;
                    } else if (makeUpper.includes('PENTAX')) {
                        if (modelUpper.includes('K-1')) {
                            sensorWidth = 36;
                            sensorHeight = 24;
                            cameraInfo = `${make} ${model} (Full Frame)`;
                        } else {
                            sensorWidth = 23.6;
                            sensorHeight = 15.6;
                            cameraInfo = `${make} ${model} (APS-C)`;
                        }
                    }
                    
                    if (sensorWidth) {
                        console.log('Found by pattern matching. Sensor:', sensorWidth + '×' + sensorHeight);
                    }
                }
            }
            // Check if it's a phone
            else if (make.match(/Apple|samsung|Google|Xiaomi|OnePlus|Huawei/i)) {
                // Try to get sensor from database
                const phoneSensors = PHONE_SENSORS[make]?.[model];
                
                if (phoneSensors && focalLength) {
                    // Guess which camera based on focal length
                    if (focalLength < 3) {
                        sensorData = phoneSensors.ultrawide || {w: 5.7, h: 4.3};
                        cameraInfo = `${make} ${model} (Ultra-wide)`;
                    } else if (focalLength < 10) {
                        sensorData = phoneSensors.main || {w: 8.0, h: 6.0};
                        cameraInfo = `${make} ${model} (Main)`;
                    } else {
                        sensorData = phoneSensors.tele || {w: 4.0, h: 3.0};
                        cameraInfo = `${make} ${model} (Telephoto)`;
                    }
                    sensorWidth = sensorData.w;
                    sensorHeight = sensorData.h;
                } else {
                    // Use defaults based on focal length patterns with 4:3 aspect ratio
                    if (focalLength < 3) {
                        sensorWidth = 5.7;
                        sensorHeight = 4.3;
                        cameraInfo = `${make} Phone (Ultra-wide, estimated)`;
                    } else if (focalLength < 10) {
                        sensorWidth = 8.0;
                        sensorHeight = 6.0;
                        cameraInfo = `${make} Phone (Main, estimated)`;
                    } else {
                        sensorWidth = 4.0;
                        sensorHeight = 3.0;
                        cameraInfo = `${make} Phone (Telephoto, estimated)`;
                    }
                }
            }
            
            // Calculate FOV if we have sensor dimensions and focal length
            if (sensorWidth && sensorHeight && focalLength) {
                // Calculate both horizontal and vertical FOV
                fovH = (2 * Math.atan(sensorWidth / (2 * focalLength)) * 180 / Math.PI).toFixed(1);
                fovV = (2 * Math.atan(sensorHeight / (2 * focalLength)) * 180 / Math.PI).toFixed(1);
                
                // For portrait orientation, the relevant FOV for blur is the narrower dimension
                let primaryFOV = isPortrait ? fovV : fovH;
                let secondaryFOV = isPortrait ? fovH : fovV;
                detectedFieldOfView = parseFloat(primaryFOV);
                
                // Update UI with both FOVs
                document.getElementById('cameraType').textContent = cameraInfo;
                
                // Show both FOVs with clear labeling
                let fovDisplay = isPortrait 
                    ? `Vertical: ${fovV}° | Horizontal: ${fovH}°`
                    : `Horizontal: ${fovH}° | Vertical: ${fovV}°`;
                    
                document.getElementById('detectedFOV').innerHTML = fovDisplay + 
                    `<br><small style="color: #888;">(Using ${isPortrait ? 'vertical' : 'horizontal'} FOV for blur)</small>`;
                
                document.getElementById('fovOverride').value = Math.round(detectedFieldOfView);
                document.getElementById('fovInput').value = Math.round(detectedFieldOfView);
                
                // Update pixels per degree for blur calculations
                updatePixelsPerDegree();
                
                console.log('FOV calculated - H:', fovH, 'V:', fovV, 'degrees');
                console.log('Using', isPortrait ? 'vertical' : 'horizontal', 'FOV for calculations');
            } else if (focalLength35mm) {
                // Fallback: estimate from 35mm equivalent
                let fov = estimateFOVFrom35mm(focalLength35mm);
                detectedFieldOfView = fov;
                
                document.getElementById('cameraType').textContent = `${make} ${model} (35mm equiv: ${focalLength35mm}mm)`;
                document.getElementById('detectedFOV').innerHTML = `~${fov}° (estimated from 35mm equiv)<br>
                    <small style="color: #888;">Orientation: ${isPortrait ? 'Portrait' : 'Landscape'}</small>`;
                document.getElementById('fovOverride').value = Math.round(fov);
                document.getElementById('fovInput').value = Math.round(fov);
                
                updatePixelsPerDegree();
                
                console.log('FOV estimated from 35mm equiv:', fov, 'degrees');
            } else {
                document.getElementById('cameraType').textContent = 'Not detected - please set manually';
                document.getElementById('detectedFOV').innerHTML = 'Manual setting required<br>' +
                    `<small style="color: #888;">Image orientation: ${isPortrait ? 'Portrait' : 'Landscape'}</small>`;
                console.log('Could not detect camera or calculate FOV');
            }
        }

        // Estimate FOV from 35mm equivalent focal length
        function estimateFOVFrom35mm(focal35mm) {
            // Using 36mm sensor width for full frame
            return Math.round(2 * Math.atan(36 / (2 * focal35mm)) * 180 / Math.PI);
        }

        // Update pixels per degree based on detected or manual FOV
        function updatePixelsPerDegree() {
            if (originalCanvas && originalCanvas.width > 0) {
                const fov = parseFloat(document.getElementById('fovInput').value) || detectedFieldOfView;
                
                // Determine if image is portrait or landscape
                const isPortrait = originalCanvas.height > originalCanvas.width;
                
                // Use the appropriate dimension for pixels per degree calculation
                const relevantPixels = isPortrait ? originalCanvas.height : originalCanvas.width;
                const pixelsPerDegree = relevantPixels / fov;
                
                // This will be used in the blur calculations
                window.currentPixelsPerDegree = pixelsPerDegree;
                
                console.log(`Pixels per degree: ${pixelsPerDegree.toFixed(1)} (using ${isPortrait ? 'height' : 'width'} of ${relevantPixels}px)`);
            }
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            originalCanvas = document.getElementById('originalCanvas');
            simulatedCanvas = document.getElementById('simulatedCanvas');
            originalCtx = originalCanvas.getContext('2d');
            simulatedCtx = simulatedCanvas.getContext('2d');
            
            setupEventListeners();
            updateDisplayValues();
            
            // FOV override controls
            const fovSlider = document.getElementById('fovOverride');
            const fovInput = document.getElementById('fovInput');
            
            fovSlider.addEventListener('input', (e) => {
                fovInput.value = e.target.value;
                detectedFieldOfView = parseFloat(e.target.value);
                updatePixelsPerDegree();
                if (originalImage) {
                    applySimulation();
                }
            });
            
            fovInput.addEventListener('change', (e) => {
                const value = Math.max(10, Math.min(180, parseFloat(e.target.value) || 60));
                fovSlider.value = value;
                e.target.value = value;
                detectedFieldOfView = value;
                updatePixelsPerDegree();
                if (originalImage) {
                    applySimulation();
                }
            });
        });

        // Event Listeners
        function setupEventListeners() {
            const uploadArea = document.getElementById('uploadArea');
            const fileInput = document.getElementById('fileInput');
            
            uploadArea.addEventListener('click', () => fileInput.click());
            fileInput.addEventListener('change', handleFileSelect);
            
            // Drag and drop
            uploadArea.addEventListener('dragover', (e) => {
                e.preventDefault();
                uploadArea.classList.add('dragover');
            });
            
            uploadArea.addEventListener('dragleave', () => {
                uploadArea.classList.remove('dragover');
            });
            
            uploadArea.addEventListener('drop', (e) => {
                e.preventDefault();
                uploadArea.classList.remove('dragover');
                const files = e.dataTransfer.files;
                if (files.length > 0) {
                    handleFile(files[0]);
                }
            });
            
            // Slider updates
            document.getElementById('acuity').addEventListener('input', updateDisplayValues);
            document.getElementById('contrast').addEventListener('input', updateDisplayValues);
            document.getElementById('saturation').addEventListener('input', updateDisplayValues);
            document.getElementById('fieldLoss').addEventListener('input', updateDisplayValues);
            document.getElementById('condition').addEventListener('change', updateConditionPresets);
        }

        // File handling
        function handleFileSelect(e) {
            const file = e.target.files[0];
            if (file) {
                handleFile(file);
            }
        }

        function handleFile(file) {
            if (!file.type.startsWith('image/')) {
                alert('Please select an image file');
                return;
            }
            
            // Extract EXIF data with better error handling
            EXIF.getData(file, function() {
                const exifData = EXIF.getAllTags(this);
                console.log('EXIF Data:', exifData); // Debug log
                
                // Show EXIF info in console for debugging
                if (exifData.Make) {
                    console.log('Camera Make:', exifData.Make);
                    console.log('Camera Model:', exifData.Model);
                    console.log('Focal Length:', exifData.FocalLength);
                    console.log('35mm Focal Length:', exifData.FocalLengthIn35mmFilm);
                    console.log('F-Stop:', exifData.FNumber);
                    console.log('ISO:', exifData.ISOSpeedRatings);
                }
                
                detectCameraAndFOV(exifData);
            });
            
            const reader = new FileReader();
            reader.onload = (e) => {
                const img = new Image();
                img.onload = () => {
                    originalImage = img;
                    displayOriginalImage();
                    applySimulation();
                };
                img.src = e.target.result;
            };
            reader.readAsDataURL(file);
        }

        function displayOriginalImage() {
            if (!originalImage) return;
            
            // Limit size for performance
            const maxWidth = 1200;  // Increased for better quality
            const maxHeight = 900;   // Good balance of quality and performance
            
            let width = originalImage.width;
            let height = originalImage.height;
            
            if (width > maxWidth || height > maxHeight) {
                const ratio = Math.min(maxWidth / width, maxHeight / height);
                width *= ratio;
                height *= ratio;
            }
            
            originalCanvas.width = width;
            originalCanvas.height = height;
            simulatedCanvas.width = width;
            simulatedCanvas.height = height;
            
            originalCtx.drawImage(originalImage, 0, 0, width, height);
        }

        // Vision simulation functions
        function applySimulation() {
            if (!originalImage) {
                alert('Please upload an image first');
                return;
            }
            
            showLoading(true);
            
            // Use setTimeout to ensure loading indicator appears
            setTimeout(() => {
                // Get parameters
                const logMAR = parseFloat(document.getElementById('acuity').value);
                const pelliRobson = parseFloat(document.getElementById('contrast').value);
                const saturation = parseFloat(document.getElementById('saturation').value) / 100;
                const fieldLoss = parseFloat(document.getElementById('fieldLoss').value) / 100;
                
                const yellowing = document.getElementById('yellowing').checked;
                const floaters = document.getElementById('floaters').checked;
                const centralScotoma = document.getElementById('centralScotoma').checked;
                
                // Copy original to simulated
                simulatedCtx.drawImage(originalCanvas, 0, 0);
                
                // Get image data
                let imageData = simulatedCtx.getImageData(0, 0, simulatedCanvas.width, simulatedCanvas.height);
                
                // Apply blur based on acuity
                if (logMAR > 0) {
                    imageData = applyAcuityBlur(imageData, logMAR, false);
                }
                
                // Apply contrast reduction
                if (pelliRobson < 2.0) {
                    imageData = applyContrastReduction(imageData, pelliRobson);
                }
                
                // Apply saturation reduction
                if (saturation < 1.0) {
                    imageData = applySaturationReduction(imageData, saturation);
                }
                
                // Apply condition-specific effects
                if (yellowing) {
                    imageData = applyYellowing(imageData);
                }
                
                if (floaters) {
                    imageData = applyFloaters(imageData);
                }
                
                if (centralScotoma) {
                    imageData = applyCentralScotoma(imageData);
                }
                
                if (fieldLoss > 0) {
                    imageData = applyPeripheralFieldLoss(imageData, fieldLoss);
                }
                
                // Put processed image back
                simulatedCtx.putImageData(imageData, 0, 0);
                
                showLoading(false);
            }, 10);
        }

        function applyAcuityBlur(imageData, logMAR, isFisheye) {
    // Compute sigma (in degrees) so that MTF(FC)=0.5 at the acuity cutoff FC (cycles/deg)
    // FC = FPN * 10^{-logMAR}, with FPN≈30 cpd for normal acuity
    const FPN = 30;
    const cyclesPerDegree = FPN * Math.pow(10, -logMAR);
    let sigmaDeg = 0.1875 / Math.max(1e-6, cyclesPerDegree); // 0.1875 gives MTF(FC)=0.5
    // Convert to pixels using the orientation-correct pixels/degree if available
    const fallbackFOV = (typeof detectedFieldOfView === 'number' ? detectedFieldOfView : 60);
    const pixelsPerDegree = (typeof window.currentPixelsPerDegree === 'number' && window.currentPixelsPerDegree > 0)
        ? window.currentPixelsPerDegree
        : (imageData.width / fallbackFOV);
    const sigmaPx = sigmaDeg * pixelsPerDegree;
    return gaussianBlur(imageData, sigmaPx, isFisheye);
}

        function gaussianBlur(imageData, sigma, isFisheye = false) {
            const width = imageData.width;
            const height = imageData.height;
            const data = imageData.data;
            const output = new Uint8ClampedArray(data);
            
            // Limit sigma for performance
            sigma = Math.min(sigma, 20);
            
            // Create Gaussian kernel
            const kernelSize = Math.min(Math.ceil(sigma * 3) * 2 + 1, 31); // Cap kernel size
            const kernel = createGaussianKernel(sigma);
            
            // If fisheye, apply radially-varying blur
            if (isFisheye) {
                const centerX = width / 2;
                const centerY = height / 2;
                const maxRadius = Math.min(width, height) / 2;
                
                for (let y = 0; y < height; y++) {
                    for (let x = 0; x < width; x++) {
                        const dx = x - centerX;
                        const dy = y - centerY;
                        const radius = Math.sqrt(dx * dx + dy * dy);
                        const angle = 2 * Math.asin(Math.min(1, radius / (2 * maxRadius)));
                        const localSigma = sigma * (1 + angle / (Math.PI / 2) * 0.5);
                        
                        applyLocalBlur(data, output, x, y, width, height, localSigma);
                    }
                }
            } else {
                // Apply uniform blur
                for (let y = 0; y < height; y++) {
                    for (let x = 0; x < width; x++) {
                        applyLocalBlur(data, output, x, y, width, height, sigma);
                    }
                }
            }
            
            imageData.data.set(output);
            return imageData;
        }

        function createGaussianKernel(sigma) {
            const size = Math.min(Math.ceil(sigma * 3) * 2 + 1, 31); // Cap size for performance
            const kernel = [];
            const center = Math.floor(size / 2);
            let sum = 0;
            
            for (let i = 0; i < size; i++) {
                kernel[i] = [];
                for (let j = 0; j < size; j++) {
                    const x = i - center;
                    const y = j - center;
                    const value = Math.exp(-(x * x + y * y) / (2 * sigma * sigma));
                    kernel[i][j] = value;
                    sum += value;
                }
            }
            
            // Normalize
            for (let i = 0; i < size; i++) {
                for (let j = 0; j < size; j++) {
                    kernel[i][j] /= sum;
                }
            }
            
            return kernel;
        }

        function applyLocalBlur(input, output, x, y, width, height, sigma) {
            const kernelSize = Math.min(Math.ceil(sigma * 3) * 2 + 1, 31); // Cap size
            const halfSize = Math.floor(kernelSize / 2);
            const kernel = createGaussianKernel(sigma);
            
            let r = 0, g = 0, b = 0;
            let weightSum = 0;
            
            for (let ky = -halfSize; ky <= halfSize; ky++) {
                for (let kx = -halfSize; kx <= halfSize; kx++) {
                    const px = Math.min(Math.max(x + kx, 0), width - 1);
                    const py = Math.min(Math.max(y + ky, 0), height - 1);
                    const idx = (py * width + px) * 4;
                    const weight = kernel[ky + halfSize][kx + halfSize];
                    
                    r += input[idx] * weight;
                    g += input[idx + 1] * weight;
                    b += input[idx + 2] * weight;
                    weightSum += weight;
                }
            }
            
            const outputIdx = (y * width + x) * 4;
            output[outputIdx] = r / weightSum;
            output[outputIdx + 1] = g / weightSum;
            output[outputIdx + 2] = b / weightSum;
            output[outputIdx + 3] = input[outputIdx + 3];
        }

        function applyContrastReduction(imageData, pelliRobson) {
    const data = imageData.data;
    // Map PR (log10 sensitivity) to a relative peak sensitivity factor vs ~1.95 normal
    const S_peak = Math.pow(10, pelliRobson);
    const S_norm = Math.pow(10, 1.95);
    const factor = Math.min(1, S_peak / S_norm); // 1.0 at normal (~1.95), lower otherwise
    // Calculate mean luminance
    let meanLum = 0;
    for (let i = 0; i < data.length; i += 4) {
        meanLum += 0.299 * data[i] + 0.587 * data[i + 1] + 0.114 * data[i + 2];
    }
    meanLum /= (data.length / 4);
    // Apply contrast scaling about the mean
    for (let i = 0; i < data.length; i += 4) {
        let r = data[i], g = data[i+1], b = data[i+2];
        const lum = 0.299 * r + 0.587 * g + 0.114 * b;
        const dr = r - lum, dg = g - lum, db = b - lum;
        r = lum + dr * factor; g = lum + dg * factor; b = lum + db * factor;
        data[i] = Math.max(0, Math.min(255, r));
        data[i+1] = Math.max(0, Math.min(255, g));
        data[i+2] = Math.max(0, Math.min(255, b));
    }
    return imageData;
}
            meanLum /= (data.length / 4);
            
            // Apply contrast reduction
            for (let i = 0; i < data.length; i += 4) {
                data[i] = meanLum + (data[i] - meanLum) * factor;
                data[i + 1] = meanLum + (data[i + 1] - meanLum) * factor;
                data[i + 2] = meanLum + (data[i + 2] - meanLum) * factor;
            }
            
            return imageData;
        }

        function applySaturationReduction(imageData, saturation) {
            const data = imageData.data;
            
            for (let i = 0; i < data.length; i += 4) {
                const r = data[i];
                const g = data[i + 1];
                const b = data[i + 2];
                
                // Convert to grayscale
                const gray = 0.299 * r + 0.587 * g + 0.114 * b;
                
                // Mix with original based on saturation
                data[i] = gray + (r - gray) * saturation;
                data[i + 1] = gray + (g - gray) * saturation;
                data[i + 2] = gray + (b - gray) * saturation;
            }
            
            return imageData;
        }

        function applyYellowing(imageData, strength = 1.0) {
  const data = imageData.data;
  const Tm = [1.00, 0.92, 0.80], Ts = [1.00, 0.75, 0.40];
  const T = [0,1,2].map(i => Tm[i] + (Ts[i]-Tm[i]) * Math.max(0, Math.min(1, strength)));
  const Yn = 0.299*1 + 0.587*1 + 0.114*1;
  const Yt = 0.299*T[0] + 0.587*T[1] + 0.114*T[2];
  const k = Yn / Yt;
  for (let i=0;i<data.length;i+=4){
    data[i]   = Math.min(255, data[i]   * T[0] * k);
    data[i+1] = Math.min(255, data[i+1] * T[1] * k);
    data[i+2] = Math.min(255, data[i+2] * T[2] * k);
  }
  return imageData;
}
return imageData;
        }

        function applyFloaters(imageData) {
            const width = imageData.width;
            const height = imageData.height;
            const data = imageData.data;
            
            // Add random dark spots
            const numFloaters = Math.floor(Math.random() * 10) + 5;
            
            for (let f = 0; f < numFloaters; f++) {
                const x = Math.floor(Math.random() * width);
                const y = Math.floor(Math.random() * height);
                const size = Math.floor(Math.random() * 5) + 2;
                
                for (let dy = -size; dy <= size; dy++) {
                    for (let dx = -size; dx <= size; dx++) {
                        const px = Math.min(Math.max(x + dx, 0), width - 1);
                        const py = Math.min(Math.max(y + dy, 0), height - 1);
                        const dist = Math.sqrt(dx * dx + dy * dy);
                        
                        if (dist <= size) {
                            const idx = (py * width + px) * 4;
                            const darkness = 1 - (dist / size) * 0.5;
                            data[idx] *= darkness * 0.3;
                            data[idx + 1] *= darkness * 0.3;
                            data[idx + 2] *= darkness * 0.3;
                        }
                    }
                }
            }
            
            return imageData;
        }

        function applyCentralScotoma(imageData) {
            const width = imageData.width;
            const height = imageData.height;
            const data = imageData.data;
            const centerX = width / 2;
            const centerY = height / 2;
            const radius = Math.min(width, height) * 0.15;
            const feather = radius * 0.5;
            
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const dx = x - centerX;
                    const dy = y - centerY;
                    const dist = Math.sqrt(dx * dx + dy * dy);
                    
                    if (dist < radius + feather) {
                        const idx = (y * width + x) * 4;
                        let factor = 1;
                        
                        if (dist < radius) {
                            factor = 0;
                        } else {
                            factor = (dist - radius) / feather;
                        }
                        
                        data[idx] *= factor;
                        data[idx + 1] *= factor;
                        data[idx + 2] *= factor;
                    }
                }
            }
            
            return imageData;
        }

        function applyPeripheralFieldLoss(imageData, amount) {
    const width = imageData.width;
    const height = imageData.height;
    const data = imageData.data;

    // Compute horizontal and vertical FOV in radians
    const hfovDeg = (typeof detectedFieldOfView === 'number' ? detectedFieldOfView : 60);
    const hfov = hfovDeg * Math.PI / 180;
    const vfov = 2 * Math.atan((height/width) * Math.tan(hfov/2)); // rectilinear camera

    // Choose a circular field in ANGULAR space that fits inside the frame
    const thetaMax = Math.min(hfov/2, vfov/2); // radians
    const thetaInner = (1 - amount) * thetaMax; // inner radius in radians
    const feather = 0.15 * thetaMax; // soft edge width (~15% of radius)

    const cx = width / 2, cy = height / 2;
    const tanH = Math.tan(hfov / 2);
    const tanV = Math.tan(vfov / 2);

    for (let y = 0; y < height; y++) {
        const ny = ( (y + 0.5) - cy ) / (height/2); // -1..1
        for (let x = 0; x < width; x++) {
            const nx = ( (x + 0.5) - cx ) / (width/2); // -1..1

            // Direction vector in camera space for rectilinear projection
            const tx = nx * tanH;
            const ty = ny * tanV;
            const theta = Math.atan(Math.hypot(tx, ty)); // angle from optical axis

            let w = 1.0;
            if (theta > thetaInner) {
                const t = Math.min(1, (theta - thetaInner) / Math.max(1e-6, feather));
                w = 1 - t; // linear ramp to 0 at the edge
                if (theta >= thetaMax) w = 0;
            }

            const idx = (y * width + x) * 4;
            data[idx] *= w;
            data[idx+1] *= w;
            data[idx+2] *= w;
        }
    }
    return imageData;
}
}
            }
            
            return imageData;
        }

        // UI update functions
        function updateDisplayValues() {
            const logMAR = parseFloat(document.getElementById('acuity').value);
            const snellen = logMARToSnellen(logMAR);
            const cyclesPerDegree = 30 * Math.pow(10, -logMAR);
            const sigma = 0.5 / cyclesPerDegree;
            
            // Calculate pixel-based sigma (assuming 800px width = 60 degree FOV)
            const pixelSigma = sigma * (800 / 60);
            
            document.getElementById('acuityValue').textContent = snellen;
            document.getElementById('contrastValue').textContent = document.getElementById('contrast').value;
            document.getElementById('saturationValue').textContent = document.getElementById('saturation').value + '%';
            document.getElementById('fieldLossValue').textContent = document.getElementById('fieldLoss').value + '%';
            
            document.getElementById('logmarInfo').textContent = logMAR.toFixed(2);
            document.getElementById('cpdInfo').textContent = cyclesPerDegree.toFixed(2);
            document.getElementById('sigmaInfo').textContent = pixelSigma.toFixed(1);
        }

        function logMARToSnellen(logMAR) {
            const denominator = Math.round(20 * Math.pow(10, logMAR));
            return `20/${denominator}`;
        }

        function updateConditionPresets() {
    const condition = document.getElementById('condition').value;

    // DeVAS-like severity presets (Thompson et al. 2021)
    const presets = {
        // Acuity-only preset: we keep user-specified contrast/saturation/etc.
        acuity: { logMAR: 0.35, contrast: 1.48, saturation: 1.0, yellowing: false, floaters: false, scotoma: false, field: 0 },
        mild:   { logMAR: 0.35, contrast: 1.48, saturation: 0.95, yellowing: false, floaters: false, scotoma: false, field: 0 },
        moderate:{ logMAR: 0.75, contrast: 1.20, saturation: 0.9, yellowing: false, floaters: false, scotoma: false, field: 0 },
        severe: { logMAR: 1.15, contrast: 0.90, saturation: 0.85, yellowing: false, floaters: false, scotoma: false, field: 0 },
        profound:{ logMAR: 1.55, contrast: 0.60, saturation: 0.8, yellowing: false, floaters: false, scotoma: false, field: 0 },
        cataracts: { logMAR: 0.5, contrast: 1.20, saturation: 0.9, yellowing: true, floaters: false, scotoma: false, field: 0 },
        diabetic:  { logMAR: 0.6, contrast: 1.1,  saturation: 0.9, yellowing: false, floaters: true, scotoma: false, field: 10 },
        macular:   { logMAR: 0.8, contrast: 1.0,  saturation: 0.85, yellowing: false, floaters: false, scotoma: true, field: 0 },
        glaucoma:  { logMAR: 0.6, contrast: 1.2,  saturation: 0.9, yellowing: false, floaters: false, scotoma: false, field: 40 },
        custom: null
    };

    const preset = presets[condition];
    if (preset) {
        document.getElementById('acuity').value = preset.logMAR;
        document.getElementById('contrast').value = preset.contrast;
        document.getElementById('saturation').value = Math.round(preset.saturation * 100);
        document.getElementById('yellowing').checked = preset.yellowing;
        document.getElementById('floaters').checked = preset.floaters;
        document.getElementById('centralScotoma').checked = preset.scotoma;
        document.getElementById('fieldLoss').value = preset.field;

        updateDisplayValues();
        applySimulation();
    }
}
,
                cataracts: { logMAR: 0.3, contrast: 1.2, saturation: 80, yellowing: true, floaters: false, scotoma: false, field: 0 },
                diabetic: { logMAR: 0.4, contrast: 1.3, saturation: 90, yellowing: false, floaters: true, scotoma: false, field: 10 },
                macular: { logMAR: 0.6, contrast: 1.0, saturation: 70, yellowing: false, floaters: false, scotoma: true, field: 0 },
                glaucoma: { logMAR: 0.2, contrast: 1.4, saturation: 100, yellowing: false, floaters: false, scotoma: false, field: 40 },
                custom: null
            };
            
            const preset = presets[condition];
            if (preset) {
                document.getElementById('acuity').value = preset.logMAR;
                document.getElementById('contrast').value = preset.contrast;
                document.getElementById('saturation').value = preset.saturation;
                document.getElementById('fieldLoss').value = preset.field;
                document.getElementById('yellowing').checked = preset.yellowing;
                document.getElementById('floaters').checked = preset.floaters;
                document.getElementById('centralScotoma').checked = preset.scotoma;
                
                updateDisplayValues();
                
                if (originalImage) {
                    applySimulation();
                }
            }
        }

        function resetImage() {
            if (originalImage) {
                simulatedCtx.drawImage(originalCanvas, 0, 0);
            }
        }

        function downloadImage() {
            const link = document.createElement('a');
            link.download = 'vision_simulation.png';
            link.href = simulatedCanvas.toDataURL();
            link.click();
        }

        function showLoading(show) {
            document.getElementById('loading').style.display = show ? 'block' : 'none';
        }
    function applyVeilingGlare(imageData, strength = 0.25, sigmaDeg = 15) {
  const pxPerDeg = (typeof window.currentPixelsPerDegree === 'number' && window.currentPixelsPerDegree>0)
    ? window.currentPixelsPerDegree
    : (imageData.width / ((typeof detectedFieldOfView==='number'?detectedFieldOfView:60)));
  const sigmaPx = Math.max(1, sigmaDeg * pxPerDeg);
  const blurred = gaussianBlur(new ImageData(new Uint8ClampedArray(imageData.data), imageData.width, imageData.height), sigmaPx);
  const a = Math.max(0, Math.min(1, strength));
  const d = imageData.data, b = blurred.data;
  for (let i=0;i<d.length;i+=4){
    d[i]   = d[i]*(1-a)   + b[i]*a;
    d[i+1] = d[i+1]*(1-a) + b[i+1]*a;
    d[i+2] = d[i+2]*(1-a) + b[i+2]*a;
  }
  return imageData;
}

function toGrayscale(imageData) {
  const w = imageData.width, h = imageData.height, d = imageData.data;
  const g = new Float32Array(w*h);
  for (let i=0, p=0; i<d.length; i+=4, p++){
    g[p] = 0.299*d[i] + 0.587*d[i+1] + 0.114*d[i+2];
  }
  return {w, h, g};
}
function sobelMagnitude(gray) {
  const {w,h,g} = gray;
  const out = new Float32Array(w*h);
  for (let y=1;y<h-1;y++){
    for (let x=1;x<w-1;x++){
      const i = y*w + x;
      const gx = -g[i-w-1] -2*g[i-1] - g[i+w-1] + g[i-w+1] + 2*g[i+1] + g[i+w+1];
      const gy = -g[i-w-1] -2*g[i-w] - g[i-w+1] + g[i+w-1] + 2*g[i+w] + g[i+w+1];
      out[i] = Math.hypot(gx, gy);
    }
  }
  return {w,h,mag:out};
}
function applyEdgeHazardOverlay(origData, simData, sensitivity=50) {
  // sensitivity 0..100 controls how easily an edge is flagged
  const w = simData.width, h = simData.height;
  const o = toGrayscale(origData); const s = toGrayscale(simData);
  const Om = sobelMagnitude(o).mag, Sm = sobelMagnitude(s).mag;

  // thresholds
  const high = 100; // strong edge in original
  const low = 20 + (120-20)*(1 - sensitivity/100); // low threshold in simulated

  const D = simData.data;
  for (let y=1;y<h-1;y++){
    for (let x=1;x<w-1;x++){
      const i = y*w + x;
      if (Om[i] >= high && Sm[i] < low) {
        const idx = i*4;
        // overlay red marker (alpha-blend)
        D[idx]   = Math.min(255, D[idx]*0.5 + 255*0.5);
        D[idx+1] = Math.min(255, D[idx+1]*0.5 + 0*0.5);
        D[idx+2] = Math.min(255, D[idx+2]*0.5 + 0*0.5);
      }
    }
  }
  return simData;
}

</script>
</body>
</html>